Opensource models that run in frameworks


# References

Hugging Face Transformers: A library for working with Transformer-based models, including pre-trained models like BERT, GPT-2, and T5. The library provides a consistent API for working with various models, and includes tools for fine-tuning and evaluating them.

TensorFlow Hub: A repository of pre-trained TensorFlow models, including several pre-trained Transformer models like BERT and T5. The models can be easily loaded and used in TensorFlow, and the repository includes tools for evaluating and fine-tuning the models.

PyTorch Hub: A repository of pre-trained PyTorch models, including several pre-trained Transformer models like BERT and GPT-2. The models can be easily loaded and used in PyTorch, and the repository includes tools for evaluating and fine-tuning the models.

AllenNLP: A library for building and evaluating deep learning models for natural language processing tasks. The library includes several pre-trained Transformer models, including BERT and RoBERTa, and provides tools for fine-tuning and evaluating the models.

spaCy: A library for building and deploying natural language processing pipelines. The library includes pre-trained Transformer models for several NLP tasks, including text classification, named entity recognition, and dependency parsing.

These libraries provide a range of tools and resources for working with pre-trained Transformer models, including pre-trained weights, fine-tuning scripts, and evaluation metrics. They make it easy to access and use state-of-the-art models for various natural language processing tasks.


Hugging Face Transformers: https://huggingface.co/transformers/

TensorFlow Hub: https://www.tensorflow.org/hub/

PyTorch Hub: https://pytorch.org/hub/

AllenNLP: https://allennlp.org/

spaCy: https://spacy.io/
